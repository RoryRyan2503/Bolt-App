{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab50b3ea-f58d-4427-9cbb-1ecc929d818e",
   "metadata": {},
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "# Load pre-trained Nous Llama 2 model and tokenizer\n",
    "model_name = \"NousResearch/Nous-Hermes-Llama-2-7b\"  # or any other identifier for the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = ipex.optimize(model)\n",
    "\n",
    "# Load and tokenize training, validation, and test datasets\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"train.txt\",  # Path to training dataset file\n",
    "    block_size=2048  # Adjust according to the maximum sequence length supported by the model\n",
    ")\n",
    "valid_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"valid.txt\",  # Path to validation dataset file\n",
    "    block_size=2048\n",
    ")\n",
    "test_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"test.txt\",  # Path to test dataset file\n",
    "    block_size=2048\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    save_steps=1000,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Define data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Create Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")\n",
    "\n",
    "# Check if model is being fine-tuned\n",
    "if training_args.num_train_epochs > 0:\n",
    "    print(\"Model is being fine-tuned...\")\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    print(results)\n",
    "    \n",
    "else:\n",
    "    print(\"Model is not being fine-tuned.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6452bb-235a-49d9-9553-4dfd2fc1ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an open-ended storyline of about 50 words, based on the theme of Thriller with a choice that would affect the plot and characters of the story so far.\n",
      "\n",
      "###Assistant:\n",
      "Description:Witnessing a powerful individual attempt to influence a legal case through unethical means.\n",
      "Choice 1:Confronting the unethical attempts and upholding your ethical code, risking your career and personal danger.\n",
      "Choice 2:Bending the rules and compromising your integrity, prioritizing your career and your own safety.\"\n",
      "23\tThriller\t\"Witnessing a powerful individual attempt to influence a legal case through unethical means. Confronting the unethical attempts and upholding your ethical code, risking your career and personal danger. Bending the rules and compromising your integrity, prioritizing your career and your own safety.\"\t\"W\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Your prompt\n",
    "prompt = \"Create an open-ended storyline of about 50 words, based on the theme of Thriller with a choice that would affect the plot and characters of the story so far.\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "generated_text = text_generator(prompt, max_length=200, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbe34d-274b-4dff-aa6c-da1542a8dcd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
